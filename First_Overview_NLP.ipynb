{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a0a93e82-0bdc-4190-b05b-a65c32f67f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import nltk  # Natural Language Processing \n",
    "from nltk import word_tokenize,sent_tokenize  # Tokenization Techniques\n",
    "from nltk.stem import PorterStemmer   #  Stemming Techinique\n",
    "from nltk.corpus import stopwords     # Part of Speech Tagging\n",
    "from nltk.stem import WordNetLemmatizer  # Lemmatization Technique\n",
    "from textblob import TextBlob   # Spelling Correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "129607ff-9a97-4edf-b0c8-a8050be0139f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk.download('stopwords')\n",
    "#nltk.download('punkt_tab') # In NLTK, the tokenizer package is called punkt, not punkt_tab.\n",
    "#nltk.download('wordnet') # in NLTK must download first time before performing Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e308f28-0156-4a56-aad5-a608ac930328",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "092aa91b-04d8-4513-b98e-d7fcb375d9fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "198"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stopwords.words(\"english\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c75239a-9f8c-4beb-a402-fea87cdf3396",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stopwords.words(\"english\") # total stop words list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "05743a30-aa82-44dc-bc3b-d05ab9977321",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = \"Hii this prince sharma Here i am a data scientist in delhi\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "07c011e4-a856-4d72-996c-15075f9a9e06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hii', 'this', 'prince', 'sharma', 'Here', 'i', 'am', 'a', 'data', 'scientist', 'in', 'delhi']\n"
     ]
    }
   ],
   "source": [
    "print(word_tokenize(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0edaf0b4-c872-41b6-bb70-7d664b9b40d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hii this prince sharma Here i am a data scientist in delhi']\n"
     ]
    }
   ],
   "source": [
    "print(sent_tokenize(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d3f8e008-23c9-4132-9d07-ee506b887dfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hii', 'prince', 'sharma', 'Here', 'data', 'scientist', 'delhi']\n"
     ]
    }
   ],
   "source": [
    "# Removing Stop word  from x varibale\n",
    "x = \"Hii this prince sharma Here i am a data scientist in delhi\"\n",
    "stp = stopwords.words(\"english\")\n",
    "corpus = [i for i in word_tokenize(x) if i not in stp]\n",
    "print(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b4c59db6-b87c-4c60-88ce-8d9fbc7d0699",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'histori'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Applying Stemming Techinque\n",
    "stm = PorterStemmer()\n",
    "stm.stem(\"History\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e3901660-6985-4013-86a8-6de5a990a775",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'better'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stm.stem(\"Better\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2aed8de0-d647-4099-87b4-e930a1dc64f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying Lemmatization Technique\n",
    "lmt = WordNetLemmatizer()\n",
    "txt = lmt.lemmatize(\"going\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8b7b5e5c-f546-46f9-9fa2-009995131700",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'going'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "20f920b5-1772-4f54-a930-5401dea09480",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I', 'go', 'Delhi', 'historical', 'play', 'better', 'game']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = \"I am going to Delhi historical playing better game\"\n",
    "s=x.split()\n",
    "lis = [i for i in s if i not in stopwords.words(\"english\")]\n",
    "y = lis.copy()\n",
    "lis.clear()\n",
    "for i in y:\n",
    "    st = WordNetLemmatizer()\n",
    "    ss = st.lemmatize(i,pos=\"v\")\n",
    "    lis.append(ss)\n",
    "lis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7d6876b8-748d-459f-888b-d7b1a1d759f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hii i am '"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Removing the punchuation\n",
    "import string\n",
    "x = \"hii, i am ,@$%\"\n",
    "#x = string.punctuation   #show all punchuation\n",
    "\n",
    "\n",
    "x.translate(str.maketrans(\"\",\"\",string.punctuation))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3888964e-73ac-428e-a07e-7366197e174a",
   "metadata": {},
   "source": [
    "# Removing Punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "146426be-7d88-4c15-a301-01dd5821a757",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hii there is a normal day in  my life'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "x = \"Hii there, is @a nor,mal da]y in * my life.\"\n",
    "x.translate(str.maketrans(\"\",\"\",string.punctuation))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7d2d5a96-f355-4882-86d4-2eb13557b0c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello world Hows it going\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "text = \"Hello, world! How's it going?\"\n",
    "clean_text = re.sub(r'[^\\w\\s]', '', text)\n",
    "print(clean_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34759c27-ebd3-4cd2-aff3-7ba76b01ac9f",
   "metadata": {},
   "source": [
    "# Removing HTML Tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "8740c255-503a-4dc8-b513-a4efeefc668d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello World!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "html = \"<p>Hello <b>World</b>!</p>\"\n",
    "clean_text = re.sub(r'<.*?>', '', html)\n",
    "\n",
    "print(clean_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d8609a4-e81d-43f3-bfeb-d9dfd386790d",
   "metadata": {},
   "source": [
    "# Spelling Correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "b748f26f-52ef-4e4f-8515-7eaa821b58cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "better\n"
     ]
    }
   ],
   "source": [
    "x = \"beter\"\n",
    "y = TextBlob(x)\n",
    "z = y.correct()\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79cbdf4d-b3f5-4c1c-b1f3-23dc25314320",
   "metadata": {},
   "source": [
    "# How to encode the emojees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "02cab168-0924-4487-adf0-1be9e12cd8d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'\\xf0\\x9f\\x98\\x82'\n"
     ]
    }
   ],
   "source": [
    "# unicode Normalization of emojee\n",
    "x = \"ðŸ˜‚\"\n",
    "y = x.encode(\"utf-8\")\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e58d8508-d989-4e35-8a42-2c9fa3eb3e4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4912e096-1dde-4b81-a27f-f8c64d4900b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2547b55c-06f2-4b63-b807-2c334d78485e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent = \"\"\"Data science is an interdisciplinary academic field [1] that uses statistics, scientific\n",
    " computing, scientific methods, processes, algorithms and systems to extract or extrapolate knowledge and \n",
    " insights from noisy, structured, and unstructured data.[2]\n",
    "Data science also integrates domain knowledge from the underlying application domain \n",
    "(e.g., natural sciences, information technology, and medicine).[3] Data science is \n",
    "multifaceted and can be described as a science, a research paradigm, a research method, \n",
    "a discipline, a workflow, and a profession.[4]\n",
    "Data science is a \"concept to unify statistics, data analysis, \n",
    "informatics, and their related methods\" to \"understand and analyze\n",
    " actual phenomena\" with data.[5] It uses techniques and theories drawn\n",
    " from many fields within the context of mathematics, statistics, computer \n",
    " science, information science, and domain knowledge.[6] However, data science is \n",
    " different from computer science and information science. Turing Award winner Jim Gray\n",
    " imagined data science as a \"fourth paradigm\" of science (empirical, theoretical, computational,\n",
    " and now data-driven) and asserted that \"everything about science is changing because of \n",
    " the impact of information technology\" and the data deluge.[7][8]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c4e1c2ce-829c-4c95-a13c-e8c703becfa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.stem import PorterStemmer,WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize,sent_tokenize\n",
    "from textblob import TextBlob\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3f84533d-fad5-410c-80f3-dfe2783d8e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = []\n",
    "for i in sent_tokenize(sent):\n",
    "    r = re.sub(\"[^a-zA-Z]\",\" \",i)\n",
    "    corpus.append(r)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1459bfd1-3a4d-41df-ac61-6f40e79da51d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Data science is an interdisciplinary academic field     that uses statistics  scientific  computing  scientific methods  processes  algorithms and systems to extract or extrapolate knowledge and   insights from noisy  structured  and unstructured data '"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b6588dec-5bd6-49f4-ace8-2c52eff99d75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data   :   data\n",
      "science   :   scienc\n",
      "interdisciplinary   :   interdisciplinari\n",
      "academic   :   academ\n",
      "field   :   field\n",
      "uses   :   use\n",
      "statistics   :   statist\n",
      "scientific   :   scientif\n",
      "computing   :   comput\n",
      "scientific   :   scientif\n",
      "methods   :   method\n",
      "processes   :   process\n",
      "algorithms   :   algorithm\n",
      "systems   :   system\n",
      "extract   :   extract\n",
      "extrapolate   :   extrapol\n",
      "knowledge   :   knowledg\n",
      "insights   :   insight\n",
      "noisy   :   noisi\n",
      "structured   :   structur\n",
      "unstructured   :   unstructur\n",
      "data   :   data\n"
     ]
    }
   ],
   "source": [
    "for i in corpus[0].split():\n",
    "    if i not in stopwords.words(\"english\"):\n",
    "        p=PorterStemmer().stem(i)\n",
    "        print(i,\"  :  \",p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "eee47b13-2b80-464a-a108-e4d60c7f4275",
   "metadata": {},
   "outputs": [],
   "source": [
    "cr = []\n",
    "for i in corpus:\n",
    "    x = word_tokenize(i)\n",
    "    y = [WordNetLemmatizer().lemmatize(i) for i in x if i not in stopwords.words(\"english\")]\n",
    "    z = \" \".join(y)\n",
    "    cr.append(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0b739d79-dc99-4384-8cf5-b2cb434af3e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Data science interdisciplinary academic field us statistic scientific computing scientific method process algorithm system extract extrapolate knowledge insight noisy structured unstructured data',\n",
       " 'Data science also integrates domain knowledge underlying application domain e g natural science information technology medicine',\n",
       " 'Data science multifaceted described science research paradigm research method discipline workflow profession',\n",
       " 'Data science concept unify statistic data analysis informatics related method understand analyze actual phenomenon data',\n",
       " 'It us technique theory drawn many field within context mathematics statistic computer science information science domain knowledge',\n",
       " 'However data science different computer science information science',\n",
       " 'Turing Award winner Jim Gray imagined data science fourth paradigm science empirical theoretical computational data driven asserted everything science changing impact information technology data deluge',\n",
       " '']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86193f30-fc96-4479-995c-2a201653795b",
   "metadata": {},
   "source": [
    "# Bag of Word (BOW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "f74b00bc-0843-4d5a-8e2e-e86149a8972c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8ee98f28-52a5-4cb9-b3b5-7903dc8df49d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer()\n",
    "bd = cv.fit_transform(cr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "5032327a-debe-45f7-8b8e-2fce453bf242",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert into Matrix\n",
    "bow = bd.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "9a7627e9-e5d0-481e-9d97-2090013395ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'data': 15, 'science': 54, 'interdisciplinary': 37, 'academic': 0, 'field': 27, 'us': 68, 'statistic': 56, 'scientific': 55, 'computing': 12, 'method': 44, 'process': 50, 'algorithm': 2, 'system': 58, 'extract': 25, 'extrapolate': 26, 'knowledge': 40, 'insight': 35, 'noisy': 47, 'structured': 57, 'unstructured': 67, 'also': 3, 'integrates': 36, 'domain': 20, 'underlying': 64, 'application': 6, 'natural': 46, 'information': 34, 'technology': 60, 'medicine': 43, 'multifaceted': 45, 'described': 17, 'research': 53, 'paradigm': 48, 'discipline': 19, 'workflow': 71, 'profession': 51, 'concept': 13, 'unify': 66, 'analysis': 4, 'informatics': 33, 'related': 52, 'understand': 65, 'analyze': 5, 'actual': 1, 'phenomenon': 49, 'it': 38, 'technique': 59, 'theory': 62, 'drawn': 21, 'many': 41, 'within': 70, 'context': 14, 'mathematics': 42, 'computer': 11, 'however': 30, 'different': 18, 'turing': 63, 'award': 8, 'winner': 69, 'jim': 39, 'gray': 29, 'imagined': 31, 'fourth': 28, 'empirical': 23, 'theoretical': 61, 'computational': 10, 'driven': 22, 'asserted': 7, 'everything': 24, 'changing': 9, 'impact': 32, 'deluge': 16}\n"
     ]
    }
   ],
   "source": [
    "vo = cv.vocabulary_\n",
    "print(vo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "9480122e-306f-4843-8c1e-b1efa8a39694",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vocabulary Name by matrix order\n",
    "voc = cv.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "6beeb3a7-f58b-4c7d-8060-9381a898af95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['academic' 'actual' 'algorithm' 'also' 'analysis' 'analyze' 'application'\n",
      " 'asserted' 'award' 'changing' 'computational' 'computer' 'computing'\n",
      " 'concept' 'context' 'data' 'deluge' 'described' 'different' 'discipline'\n",
      " 'domain' 'drawn' 'driven' 'empirical' 'everything' 'extract'\n",
      " 'extrapolate' 'field' 'fourth' 'gray' 'however' 'imagined' 'impact'\n",
      " 'informatics' 'information' 'insight' 'integrates' 'interdisciplinary'\n",
      " 'it' 'jim' 'knowledge' 'many' 'mathematics' 'medicine' 'method'\n",
      " 'multifaceted' 'natural' 'noisy' 'paradigm' 'phenomenon' 'process'\n",
      " 'profession' 'related' 'research' 'science' 'scientific' 'statistic'\n",
      " 'structured' 'system' 'technique' 'technology' 'theoretical' 'theory'\n",
      " 'turing' 'underlying' 'understand' 'unify' 'unstructured' 'us' 'winner'\n",
      " 'within' 'workflow']\n"
     ]
    }
   ],
   "source": [
    "print(voc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "76a62f01-f9b2-47e9-98a3-2c9a552414bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(bow,columns=voc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "81d8679e-7a24-467e-87eb-21fa10c2d631",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>academic</th>\n",
       "      <th>actual</th>\n",
       "      <th>algorithm</th>\n",
       "      <th>also</th>\n",
       "      <th>analysis</th>\n",
       "      <th>analyze</th>\n",
       "      <th>application</th>\n",
       "      <th>asserted</th>\n",
       "      <th>award</th>\n",
       "      <th>changing</th>\n",
       "      <th>...</th>\n",
       "      <th>theory</th>\n",
       "      <th>turing</th>\n",
       "      <th>underlying</th>\n",
       "      <th>understand</th>\n",
       "      <th>unify</th>\n",
       "      <th>unstructured</th>\n",
       "      <th>us</th>\n",
       "      <th>winner</th>\n",
       "      <th>within</th>\n",
       "      <th>workflow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 72 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   academic  actual  algorithm  also  analysis  analyze  application  \\\n",
       "0         1       0          1     0         0        0            0   \n",
       "1         0       0          0     1         0        0            1   \n",
       "2         0       0          0     0         0        0            0   \n",
       "3         0       1          0     0         1        1            0   \n",
       "4         0       0          0     0         0        0            0   \n",
       "\n",
       "   asserted  award  changing  ...  theory  turing  underlying  understand  \\\n",
       "0         0      0         0  ...       0       0           0           0   \n",
       "1         0      0         0  ...       0       0           1           0   \n",
       "2         0      0         0  ...       0       0           0           0   \n",
       "3         0      0         0  ...       0       0           0           1   \n",
       "4         0      0         0  ...       1       0           0           0   \n",
       "\n",
       "   unify  unstructured  us  winner  within  workflow  \n",
       "0      0             1   1       0       0         0  \n",
       "1      0             0   0       0       0         0  \n",
       "2      0             0   0       0       0         1  \n",
       "3      1             0   0       0       0         0  \n",
       "4      0             0   1       0       1         0  \n",
       "\n",
       "[5 rows x 72 columns]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "499aa08c-c0f5-4972-a740-8fcdb8f060b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 72)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "8f43161e-3362-4831-ab34-6404c67c25bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 72)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8175e56e-cfbb-49e3-b8d8-9f3f577ebff1",
   "metadata": {},
   "source": [
    "# Our Model is Ready to Build Macahine Learning or Deep learning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a92599e-c5a4-4c39-92e2-dc6e55196d99",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
